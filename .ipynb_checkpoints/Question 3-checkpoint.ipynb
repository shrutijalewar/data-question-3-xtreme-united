{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import fiona\n",
    "from shapely.geometry import Point\n",
    "from IPython import display\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scraping data from Wikipedia using beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating wikipedia link\n",
    "request = urllib.request.Request('https://en.wikipedia.org/wiki/List_of_deadly_earthquakes_since_1900')\n",
    "result = urllib.request.urlopen(request)\n",
    "resulttext = result.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using BeautifulSoup to import and parse data\n",
    "soup = BS(resulttext, 'html.parser')\n",
    "#soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the earthquake table using it's unique class\n",
    "table = soup.find('table', class_ = 'sortable wikitable')\n",
    "\n",
    "## Find all rows within the table\n",
    "table = table.find_all('tr')\n",
    "\n",
    "## Empty data list to store table values\n",
    "data = []\n",
    "\n",
    "## Loop that looks for table data from rows, then strips the text and stores it as a list\n",
    "for row in table:\n",
    "    cells = row.find_all('td')\n",
    "    cells = [ele.text.strip() for ele in cells]\n",
    "    data.append(cells)\n",
    "\n",
    "## Create a DataFrame from our stripped data\n",
    "eq_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Rename column headers\n",
    "eq_df.columns = ['origin','country','lat','long','depth_km','magnitude','sec_effects','shaking_death','pde_total','utsu_total','em_total','other_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop the empty first row\n",
    "eq_df = eq_df.drop(0,0)\n",
    "\n",
    "## Rename columns\n",
    "eq_columns = ['origin','country','lat','long','depth_km','magnitude','sec_effects','shaking_death','pde_total','utsu_total','em_total','other_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Regex function\n",
    "def eq_reg(eq_col, reg_phrase):\n",
    "    eq_df[eq_col] = eq_df[eq_col].str.replace(reg_phrase, '')\n",
    "\n",
    "## Cleaning columns\n",
    "eq_reg('magnitude', '([a-zA-Z])')\n",
    "eq_reg('magnitude','\\[..\\]')\n",
    "eq_reg('other_deaths', '\\[.*\\]')\n",
    "eq_reg('em_total', '\\[7\\].')\n",
    "eq_reg('country', '\\([^\\)]*\\)*')\n",
    "eq_reg('other_deaths', '\\([^\\)]*\\)*')\n",
    "eq_reg('other_deaths', '\\+')\n",
    "eq_reg('other_deaths', '26271 26000')\n",
    "eq_reg('other_deaths', '231000* 283000* 227898*')\n",
    "eq_reg('other_deaths', '\\*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converts column to float\n",
    "def float_convert(df,col):\n",
    "    df[col] = pd.to_numeric(df[col], errors ='coerce')\n",
    "\n",
    "## Float conversions\n",
    "float_convert(eq_df, 'pde_total')\n",
    "float_convert(eq_df, 'utsu_total')\n",
    "float_convert(eq_df, 'em_total')\n",
    "float_convert(eq_df, 'other_deaths')\n",
    "float_convert(eq_df, 'magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Grabbing the highest value from the death columns\n",
    "eq_df['deaths'] = eq_df[['pde_total','utsu_total','em_total','other_deaths']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cleaning up empty spaces and changing to floats \n",
    "eq_df[eq_df['lat'] == ''] = np.nan\n",
    "eq_df[eq_df['long'] == ''] = np.nan\n",
    "\n",
    "## Drop na's\n",
    "eq_df= eq_df.dropna(subset=['lat','long','deaths'])\n",
    "\n",
    "## Additional float conversions\n",
    "float_convert(eq_df, 'lat')\n",
    "float_convert(eq_df, 'long')\n",
    "float_convert(eq_df, 'deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting wikipedia data to a Point Geometry column for Geopandas\n",
    "geometry = [Point(xy) for xy in zip(eq_df.long, eq_df.lat)]\n",
    "df = eq_df.drop(['long', 'lat'], axis=1)\n",
    "crs = {'init': 'epsg:4326'}\n",
    "eq_df = GeoDataFrame(eq_df, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bringing in live data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## API site: https://earthquake.usgs.gov/fdsnws/event/1/#format-geojson\n",
    "\n",
    "url = 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=2.0&orderby=time&limit=5000'\n",
    "request = requests.get(url)\n",
    "b = bytes(request.content)\n",
    "with fiona.BytesCollection(b) as f:\n",
    "    crs = f.crs\n",
    "    gdf = gpd.GeoDataFrame.from_features(f, crs=crs)\n",
    "\n",
    "live_df = gdf\n",
    "# live_df.to_csv('/Users/Justin/Code/data-question-3-xtreme-united/live_eq_api_return.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ">Created a function that uses the slider to filter the table by magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use a built-in world shp file\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First, check if slider value is greater than the max magnitude value in the live data\n",
    "## If so, return only the value for the wikipedia data so the function doesn't return an error\n",
    "## NOTE - colorbar starts with slider value as a minimum\n",
    "\n",
    "def mag_slider(x):\n",
    "    clear_output(wait=True)\n",
    "    pylab.rcParams['figure.figsize'] = 20, 20\n",
    "    base = world.plot(color='lightgray', edgecolor='gray')\n",
    "    fig = base.get_figure()\n",
    "    base.axis('off')\n",
    "    space = make_axes_locatable(base)\n",
    "    loc = space.append_axes('right', size='3%', pad=0.01)\n",
    "    sm = plt.cm.ScalarMappable(cmap='jet', norm=plt.Normalize(vmin=x, vmax=10.0))\n",
    "    sm._A = []\n",
    "    fig.colorbar(sm,cax=loc)\n",
    "    if x < live_df['mag'].max():\n",
    "        for row in eq_df:\n",
    "            eq_bool = x < eq_df['magnitude']\n",
    "            eq_table = eq_df[eq_bool==True]\n",
    "            eq_table.plot(ax=base, marker='o', alpha = 0.3, column = 'magnitude', cmap = 'jet', markersize = 10);\n",
    "        for row in live_df:\n",
    "            live_bool = x < live_df['mag']\n",
    "            live_table = live_df[live_bool==True]\n",
    "            live_table.plot(ax=base, marker='D', alpha = 0.3, column ='mag', cmap = 'jet', markersize = 10);\n",
    "        return plt.show()\n",
    "    elif x < eq_df['magnitude'].max():\n",
    "        for row in eq_df:\n",
    "            eq_bool = x < eq_df['magnitude']\n",
    "            eq_table = eq_df[eq_bool==True]\n",
    "            eq_table.plot(ax=base, marker='o', alpha = 0.3, column = 'magnitude', cmap = 'jet', markersize = 10);\n",
    "        return plt.show()\n",
    "    else:\n",
    "        print('Magnitude too high - select lower magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ecc1ca049f4758806428c75cc07674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mag = widgets.FloatSlider(\n",
    "    value=4.5,\n",
    "    min=1.0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Magnitude',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")\n",
    "\n",
    "## interact(function name, function input = slider)\n",
    "\n",
    "widgets.interact(mag_slider, x = mag);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function looks for country name to match the country name in the wikipedia data\n",
    "## Live data stores the country name in the title column, along with other data, so str.contains is used\n",
    "\n",
    "def country_drop(x):\n",
    "    clear_output(wait=True)\n",
    "    pylab.rcParams['figure.figsize'] = 20, 20\n",
    "    country = world.loc[world.name == x]\n",
    "    base = country.plot(color='lightgray', edgecolor='gray')\n",
    "    fig = base.get_figure()\n",
    "    base.axis('off')\n",
    "    for row in eq_df:\n",
    "        eq_bool = (x == eq_df['country'])\n",
    "        eq_table = eq_df[eq_bool==True]\n",
    "        eq_table.plot(ax=base, marker='o', alpha = 0.6, column = 'magnitude', cmap = 'jet', markersize = 40)\n",
    "        space = make_axes_locatable(base)\n",
    "        loc = space.append_axes('right', size='3%', pad=0.01)\n",
    "        sm = plt.cm.ScalarMappable(cmap='jet', norm=plt.Normalize(vmin=1.0, vmax=10.0))\n",
    "        sm._A = []\n",
    "        fig.colorbar(sm,cax=loc);\n",
    "    for row in live_df:\n",
    "        live_bool = (live_df[live_df[\"title\"].str.contains(x, case=False)])\n",
    "        live_table = live_df[live_bool==True]\n",
    "        live_table.plot(ax=base, marker='D', alpha = 0.6, column ='mag', cmap = 'jet', markersize = 40);\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56386cceef14465494c5cff0de46d965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eq_country = widgets.Dropdown(\n",
    "    options=[\n",
    "        'China',\n",
    "        'Japan',\n",
    "        'Pakistan',\n",
    "        'Peru',\n",
    "        'Turkey',],\n",
    "    description='Country:',\n",
    "    disabled=False,\n",
    "    readout=True,\n",
    ")\n",
    "\n",
    "widgets.interact(country_drop, x= eq_country);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
